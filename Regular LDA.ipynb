{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/ms5941/.local/lib/python3.7/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "\n",
    "import gensim\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "from gensim.models import ldamodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "THEME = 'GDP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-25 23:32:55,513 : INFO : loading Dictionary object from /work/ms5941/NLP/Temp/GDP/GDP_less_restricted.dict\n",
      "2021-04-25 23:32:55,519 : INFO : Dictionary lifecycle event {'fname': '/work/ms5941/NLP/Temp/GDP/GDP_less_restricted.dict', 'datetime': '2021-04-25T23:32:55.518595', 'gensim': '4.0.1', 'python': '3.7.7 (default, May  7 2020, 21:25:33) \\n[GCC 7.3.0]', 'platform': 'Linux-4.19.0-16-amd64-x86_64-with-debian-10.9', 'event': 'loaded'}\n"
     ]
    }
   ],
   "source": [
    "# Load dictionary and corpus\n",
    "dictionary_all = gensim.corpora.Dictionary.load(TEMP_PATH + '/%s/%s_less_restricted.dict' % (THEME, THEME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Look for ids of related words to theme in the dictionary. This will be a list of ids for each year.\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_csv(TEMP_PATH + '/%s_words.csv' % THEME.lower(), index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_name_list = dict()\n",
    "year_id_list = dict()\n",
    "for col in words.columns:\n",
    "    reqd_words = list(words[col].values) + [THEME.lower()]\n",
    "    reqd_ids = [k for k,v in dictionary_all.items() if v in reqd_words]\n",
    "    year_name_list[col] = [dictionary_all[i] for i in reqd_ids]\n",
    "    year_id_list[col] = reqd_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1996': ['inflation',\n",
       "  'figure',\n",
       "  'gdp',\n",
       "  'economists',\n",
       "  'unemployment',\n",
       "  'gross',\n",
       "  'cpi'],\n",
       " '1997': ['consumption',\n",
       "  'deficit',\n",
       "  'inflation',\n",
       "  'gdp',\n",
       "  'unemployment',\n",
       "  'gross',\n",
       "  'cpi'],\n",
       " '1998': ['consumption',\n",
       "  'deficit',\n",
       "  'inflation',\n",
       "  'gdp',\n",
       "  'employment',\n",
       "  'unemployment',\n",
       "  'cpi',\n",
       "  'eci'],\n",
       " '1999': ['deficit',\n",
       "  'inflation',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'employment',\n",
       "  'unemployment',\n",
       "  'cpi'],\n",
       " '2000': ['inflation',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'revised',\n",
       "  'economists',\n",
       "  'employment',\n",
       "  'cpi',\n",
       "  'pmi'],\n",
       " '2001': ['consumption',\n",
       "  'inflation',\n",
       "  'figure',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'revised',\n",
       "  'employment',\n",
       "  'gross',\n",
       "  'reading',\n",
       "  'cpi'],\n",
       " '2002': ['consumption',\n",
       "  'inflation',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'employment',\n",
       "  'gross',\n",
       "  'reading',\n",
       "  'cpi'],\n",
       " '2003': ['inflation', 'gdp', 'payrolls', 'jobless'],\n",
       " '2004': ['inflation', 'output', 'gdp', 'payrolls', 'jobs', 'cpi', 'pmi'],\n",
       " '2005': ['inflation',\n",
       "  'output',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'jobless',\n",
       "  'factory',\n",
       "  'cpi'],\n",
       " '2006': ['deficit',\n",
       "  'inflation',\n",
       "  'output',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'revised',\n",
       "  'jobs',\n",
       "  'cpi'],\n",
       " '2007': ['deficit', 'inflation', 'gdp', 'payrolls', 'cpi'],\n",
       " '2008': ['deficit', 'inflation', 'gdp', 'payrolls', 'cpi'],\n",
       " '2009': ['deficit', 'exports', 'inflation', 'gdp', 'payrolls', 'cpi'],\n",
       " '2010': ['consumption',\n",
       "  'deficit',\n",
       "  'inflation',\n",
       "  'output',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'cpi',\n",
       "  'pmi'],\n",
       " '2011': ['consumption',\n",
       "  'inflation',\n",
       "  'output',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'employment',\n",
       "  'reading',\n",
       "  'cpi',\n",
       "  'pmi'],\n",
       " '2012': ['deficit', 'inflation', 'gdp', 'payrolls', 'cpi', 'pmi', 'growth'],\n",
       " '2013': ['deficit',\n",
       "  'inflation',\n",
       "  'output',\n",
       "  'gdp',\n",
       "  'payrolls',\n",
       "  'reading',\n",
       "  'cpi',\n",
       "  'pmi',\n",
       "  'growth'],\n",
       " '2014': ['deficit', 'inflation', 'gdp', 'jobs', 'cpi', 'pmi', 'growth'],\n",
       " '2015': ['deficit', 'inflation', 'gdp', 'factory', 'cpi', 'pmi', 'growth'],\n",
       " '2016': ['manufacturing',\n",
       "  'inflation',\n",
       "  'gdp',\n",
       "  'jobless',\n",
       "  'factory',\n",
       "  'cpi',\n",
       "  'pmi',\n",
       "  'growth'],\n",
       " '2017': ['inflation', 'gdp', 'cpi', 'pmi'],\n",
       " '2018': ['deficit', 'inflation', 'gdp', 'cpi', 'pmi'],\n",
       " '2019': ['deficit', 'inflation', 'gdp', 'cpi', 'surplus', 'pmi'],\n",
       " '2020': ['deficit', 'inflation', 'gdp', 'cpi', 'surplus', 'pmi']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [str(year) for year in range(START_YEAR, END_YEAR + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1996.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1997.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1998.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1999.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2000.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2001.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2002.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2003.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2004.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2005.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2006.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2007.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2008.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2009.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2010.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2011.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2012.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2013.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2014.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2015.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2016.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2017.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2018.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2019.json done!\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2020.json done!\n"
     ]
    }
   ],
   "source": [
    "good_words_count_per_year = dict()\n",
    "for year in years:\n",
    "    good_words_count_per_year[year] = []\n",
    "    with open(TOKENIZED_ARTICLES_PATH % (THEME, THEME, year)) as f:\n",
    "        a = json.load(f)\n",
    "        for article in a:\n",
    "            good_words_count_per_year[year].append(len([word for word in article if word in year_name_list[year]]))\n",
    "    print(TOKENIZED_ARTICLES_PATH % (THEME, THEME, year), 'done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1996.json done!\n",
      "Count for the year: 313 Vs original: 30085\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1997.json done!\n",
      "Count for the year: 235 Vs original: 21451\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1998.json done!\n",
      "Count for the year: 1403 Vs original: 121502\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_1999.json done!\n",
      "Count for the year: 890 Vs original: 67258\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2000.json done!\n",
      "Count for the year: 602 Vs original: 53084\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2001.json done!\n",
      "Count for the year: 691 Vs original: 57614\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2002.json done!\n",
      "Count for the year: 555 Vs original: 54160\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2003.json done!\n",
      "Count for the year: 1028 Vs original: 102461\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2004.json done!\n",
      "Count for the year: 1121 Vs original: 91690\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2005.json done!\n",
      "Count for the year: 1071 Vs original: 97347\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2006.json done!\n",
      "Count for the year: 1720 Vs original: 171795\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2007.json done!\n",
      "Count for the year: 2276 Vs original: 185017\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2008.json done!\n",
      "Count for the year: 2812 Vs original: 219047\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2009.json done!\n",
      "Count for the year: 2574 Vs original: 200514\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2010.json done!\n",
      "Count for the year: 1273 Vs original: 102891\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2011.json done!\n",
      "Count for the year: 1296 Vs original: 117472\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2012.json done!\n",
      "Count for the year: 1032 Vs original: 97383\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2013.json done!\n",
      "Count for the year: 1264 Vs original: 113546\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2014.json done!\n",
      "Count for the year: 1737 Vs original: 133759\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2015.json done!\n",
      "Count for the year: 1722 Vs original: 167170\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2016.json done!\n",
      "Count for the year: 2401 Vs original: 210787\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2017.json done!\n",
      "Count for the year: 1921 Vs original: 192112\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2018.json done!\n",
      "Count for the year: 2852 Vs original: 206492\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2019.json done!\n",
      "Count for the year: 3524 Vs original: 204138\n",
      "/work/ms5941/NLP/Temp/GDP/GDP_Articles_Tokenized_2020.json done!\n",
      "Count for the year: 623 Vs original: 53819\n"
     ]
    }
   ],
   "source": [
    "theme = 'GDP'\n",
    "\n",
    "yearly_slices = []\n",
    "for year in years:\n",
    "    # Get the 1% threshold count (the top 1% of most relevant articles)\n",
    "    x = good_words_count_per_year[year]\n",
    "    x.sort()\n",
    "    threshold = x[-int(len(x)*0.01):][0]\n",
    "    year_article_count = 0\n",
    "    with open(TOKENIZED_ARTICLES_PATH % (theme, theme, year)) as f:\n",
    "        article_index = 0\n",
    "        all_articles = json.load(f)\n",
    "        for articles in all_articles:\n",
    "            if good_words_count_per_year[year][article_index] >= threshold:\n",
    "                year_article_count += 1    \n",
    "            article_index += 1\n",
    "    yearly_slices.append(year_article_count)\n",
    "    print(TOKENIZED_ARTICLES_PATH % (theme, theme, year), 'done!')\n",
    "    print('Count for the year:', year_article_count, 'Vs original:', len(all_articles))\n",
    "\n",
    "# dictionary_all = gensim.corpora.Dictionary.load(TEMP_PATH + '/%s/%s_less_restricted.dict' % (theme, theme))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36936"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(yearly_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TEMP_PATH + '/%s/%s_yearly_slices.txt' % (THEME, THEME), 'w') as f:\n",
    "    json.dump(yearly_slices, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(TEMP_PATH + '/%s/%s_yearly_slices.txt' % (THEME, THEME), 'r') as f:\n",
    "#     yearly_slices = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[313, 235, 1403, 890, 602, 691, 555, 1028, 1121, 1071, 1720, 2276, 2812, 2574, 1273, 1296, 1032, 1264, 1737, 1722, 2401, 1921, 2852, 3524, 623]\n"
     ]
    }
   ],
   "source": [
    "print(yearly_slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-26 00:07:06,671 : INFO : loading Dictionary object from /work/ms5941/NLP/Temp/GDP/GDP_less_restricted.dict\n",
      "2021-04-26 00:07:06,676 : INFO : Dictionary lifecycle event {'fname': '/work/ms5941/NLP/Temp/GDP/GDP_less_restricted.dict', 'datetime': '2021-04-26T00:07:06.676415', 'gensim': '4.0.1', 'python': '3.7.7 (default, May  7 2020, 21:25:33) \\n[GCC 7.3.0]', 'platform': 'Linux-4.19.0-16-amd64-x86_64-with-debian-10.9', 'event': 'loaded'}\n",
      "2021-04-26 00:07:06,681 : INFO : loaded corpus index from /work/ms5941/NLP/Temp/GDP/GDP_less_restricted.mm.index\n",
      "2021-04-26 00:07:06,682 : INFO : initializing cython corpus reader from /work/ms5941/NLP/Temp/GDP/GDP_less_restricted.mm\n",
      "2021-04-26 00:07:06,684 : INFO : accepted corpus with 36936 documents, 1662 features, 4916481 non-zero entries\n"
     ]
    }
   ],
   "source": [
    "dictionary_all = gensim.corpora.Dictionary.load(TEMP_PATH + '/%s/%s_less_restricted.dict' % (THEME, THEME))\n",
    "corpus_all = gensim.corpora.MmCorpus(TEMP_PATH + '/%s/%s_less_restricted.mm' % (THEME, THEME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cum_yearly_slices = np.cumsum(yearly_slices)\n",
    "\n",
    "corpus_by_year = dict()\n",
    "corpus_by_year[START_YEAR] = corpus_all[:cum_yearly_slices[0]]\n",
    "for i in range(1, 25):\n",
    "    corpus_by_year[START_YEAR + i] = corpus_all[cum_yearly_slices[i-1]:cum_yearly_slices[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2574"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_by_year[2009]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lda_model(corpus, dictionary, num_topics=10, passes=50, \n",
    "                       iterations=400, eval_every=None, update_every=0, \n",
    "                       alpha='auto', eta='auto'):\n",
    "\n",
    "    lda = gensim.models.LdaModel(corpus=corpus, id2word=dictionary, alpha='auto', eta='auto',\n",
    "                                 iterations=iterations, num_topics=num_topics, passes=passes, \n",
    "                                 eval_every=eval_every, update_every = update_every)\n",
    "    \n",
    "    # Save lda model\n",
    "    tempfile = TEMP_PATH + '/%s/%s_LDA_model_' + '_'.join([str(num_topics), str(passes), str(iterations), str(alpha), str(eta)]) % (THEME, THEME)\n",
    "    lda.save(temp_file)\n",
    "    \n",
    "    return lda\n",
    "\n",
    "\n",
    "\n",
    "def get_topics(corpus_all, dictionary_all, corpus_by_year, num_topics=10, passes=50, iterations=400, \n",
    "               eval_every=None, update_every=0, alpha='auto', eta='auto'):\n",
    "    \"\"\"\n",
    "    Get the top topics for each year, based on an LDA model created using documents of both years\n",
    "    \n",
    "    \"\"\"\n",
    "    # Check if a model with the same config already exists. \n",
    "    # If it does, load the model instead of generating a new one\n",
    "    tempfile = TEMP_PATH + '/%s/%s_LDA_model_' % (THEME, THEME) + '_'.join([str(num_topics), str(passes), str(iterations), str(alpha), str(eta)]) \n",
    "    if os.path.exists(tempfile):\n",
    "        lda = gensim.models.LdaModel.load(tempfile)\n",
    "    else:\n",
    "        lda = generate_lda_model(corpus_all, dictionary_all, num_topics, passes, \n",
    "                                 iterations, eval_every, update_every, alpha, eta)\n",
    "\n",
    "    avg_topics_all = []\n",
    "    for year in range(START_YEAR, END_YEAR + 1):\n",
    "        avg_topic_probabilities = get_avg_topic_probabilities(lda, corpus_by_year[year], num_topics)\n",
    "        df, top_topic_words = get_top_ten_topics_for_year(year, lda, avg_topic_probabilities)\n",
    "        display(df)\n",
    "        avg_topics_all.append(avg_topic_probabilities)\n",
    "\n",
    "    # Plot avg topic distribution graphs\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(15,5))\n",
    "\n",
    "    ax[0].bar(range(len(avg_topics_all[0])), avg_topics_all[0]*100)\n",
    "    ax[1].bar(range(len(avg_topics_all[1])), avg_topics_all[1]*100)\n",
    "    plt.setp(ax, ylim=(0, 20))\n",
    "    plt.show()\n",
    "\n",
    "    return avg_topics_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-26 00:10:44,754 : INFO : using autotuned alpha, starting with [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "2021-04-26 00:10:44,756 : INFO : using serial LDA version on this node\n",
      "2021-04-26 00:10:44,758 : INFO : running batch LDA training, 10 topics, 50 passes over the supplied corpus of 36936 documents, updating model once every 36936 documents, evaluating perplexity every 0 documents, iterating 400x with a convergence threshold of 0.001000\n",
      "2021-04-26 00:10:44,998 : INFO : PROGRESS: pass 0, at document #2000/36936\n",
      "2021-04-26 00:11:07,971 : INFO : optimized alpha [0.06315659, 0.078261, 0.060452066, 0.07007666, 0.062615916, 0.059998147, 0.067888364, 0.062345702, 0.062065523, 0.05907267]\n",
      "2021-04-26 00:11:08,359 : INFO : PROGRESS: pass 0, at document #4000/36936\n",
      "2021-04-26 00:11:34,530 : INFO : optimized alpha [0.0439105, 0.0660411, 0.04510451, 0.053608447, 0.048513073, 0.046599515, 0.052789237, 0.048386104, 0.047577847, 0.0476005]\n",
      "2021-04-26 00:11:34,934 : INFO : PROGRESS: pass 0, at document #6000/36936\n",
      "2021-04-26 00:12:01,267 : INFO : optimized alpha [0.03466216, 0.04881515, 0.033572763, 0.055735223, 0.048015255, 0.03642625, 0.040665023, 0.041419625, 0.03611251, 0.036381807]\n",
      "2021-04-26 00:12:01,704 : INFO : PROGRESS: pass 0, at document #8000/36936\n",
      "2021-04-26 00:12:29,556 : INFO : optimized alpha [0.028682632, 0.045352686, 0.027997848, 0.044700522, 0.04382014, 0.028847488, 0.033820447, 0.03946678, 0.03384081, 0.03064454]\n",
      "2021-04-26 00:12:29,970 : INFO : PROGRESS: pass 0, at document #10000/36936\n",
      "2021-04-26 00:12:57,731 : INFO : optimized alpha [0.026052661, 0.036877785, 0.023197807, 0.047000147, 0.03727912, 0.024004865, 0.02919452, 0.040778175, 0.030667163, 0.025102304]\n",
      "2021-04-26 00:12:58,160 : INFO : PROGRESS: pass 0, at document #12000/36936\n",
      "2021-04-26 00:13:27,010 : INFO : optimized alpha [0.023185473, 0.031908657, 0.019946381, 0.051339276, 0.033974934, 0.021466086, 0.024537232, 0.039344814, 0.028432649, 0.021956433]\n",
      "2021-04-26 00:13:27,480 : INFO : PROGRESS: pass 0, at document #14000/36936\n",
      "2021-04-26 00:13:59,283 : INFO : optimized alpha [0.023371974, 0.032781534, 0.017955134, 0.050632726, 0.032092012, 0.019950734, 0.022816107, 0.029081073, 0.023201331, 0.022761755]\n",
      "2021-04-26 00:13:59,788 : INFO : PROGRESS: pass 0, at document #16000/36936\n",
      "2021-04-26 00:14:30,963 : INFO : optimized alpha [0.02251549, 0.030650662, 0.016103176, 0.047357496, 0.027013823, 0.017936483, 0.02249946, 0.024391705, 0.020971838, 0.026241327]\n",
      "2021-04-26 00:14:31,462 : INFO : PROGRESS: pass 0, at document #18000/36936\n",
      "2021-04-26 00:15:04,288 : INFO : optimized alpha [0.022319932, 0.031193102, 0.014711072, 0.04231564, 0.024883809, 0.01595655, 0.02296569, 0.021996737, 0.019803258, 0.027666226]\n",
      "2021-04-26 00:15:04,808 : INFO : PROGRESS: pass 0, at document #20000/36936\n",
      "2021-04-26 00:15:35,356 : INFO : optimized alpha [0.020937795, 0.03487705, 0.013832357, 0.038677868, 0.026811464, 0.014949609, 0.020475421, 0.0210936, 0.017779592, 0.023785554]\n",
      "2021-04-26 00:15:35,943 : INFO : PROGRESS: pass 0, at document #22000/36936\n"
     ]
    }
   ],
   "source": [
    "avg_topics_all = get_topics(corpus_all, dictionary_all, corpus_by_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
